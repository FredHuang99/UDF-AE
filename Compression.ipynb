{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(68386816,)\n",
      "(2087, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('kitchen.hdf5','r')\n",
    "data = np.array(f['data_mat'])\n",
    "#switch the data from signed distance field into unsigned distance field\n",
    "data[data<0] = -data[data<0]\n",
    "#present the shape of the experimental data\n",
    "print(data[data<0].shape)\n",
    "print(data[data>=0].shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE,self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1,out_channels=8,kernel_size=2,stride=2,padding=0,bias=False)\n",
    "        self.conv2 = nn.Conv3d(in_channels=8,out_channels=32,kernel_size=2,stride=2,padding=0,bias=False)\n",
    "        self.conv3 = nn.Conv3d(in_channels=32,out_channels=64,kernel_size=2,stride=2,padding=0,bias=False)\n",
    "        self.conv4 = nn.ConvTranspose3d(in_channels=64,out_channels=32,kernel_size=2,stride=2,padding=0,bias=True)\n",
    "        self.conv5 = nn.ConvTranspose3d(in_channels=32,out_channels=8,kernel_size=2,stride=2,padding=0,bias=True)\n",
    "        self.conv6 = nn.ConvTranspose3d(in_channels=8,out_channels=1,kernel_size=2,stride=2,padding=0,bias=True)\n",
    "    def forward(self,x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        x2 = F.relu(self.conv4(x1))\n",
    "        x2 = F.relu(self.conv5(x2))\n",
    "        x2 = F.relu(self.conv6(x2))\n",
    "        return x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SAE().to(device)\n",
    "net.load_state_dict(torch.load('UDF-AE.pkl'), strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the serial number of the baseline streamline randomly\n",
    "a = 50\n",
    "out_data = [a]\n",
    "#set the number of streamlines after compression to 64 32 16 8 or any number you want.\n",
    "#we can find that the answer to the problem when we set it at 8 is the top 8 numbers of the answer to the problem when we set it at 64.\n",
    "#so we can solve the case of '8' '16' '32' and '64' at the same time when we set it at 64\n",
    "#get the serial numbers of streamlines that should be retained after compression and stored them in '.npy' format.\n",
    "for i in range(64-1):\n",
    "    o = np.array(data[a])\n",
    "    io = torch.Tensor(o).to(device).view(1,1,32,32,32)\n",
    "    mo1,mo2 = net(io)\n",
    "    co = np.array(mo1.data.cpu()).flatten()\n",
    "    dic = {}\n",
    "    for j in range(len(data)):\n",
    "        m_input = torch.Tensor(np.array(data[j])).to(device).view(1,1,32,32,32)\n",
    "        i_m,i_out = net(m_input)\n",
    "        i_c = np.array(i_m.data.cpu()).flatten()\n",
    "        ans = np.sum((co-i_c)**2)/16**2\n",
    "        dic[j] = ans\n",
    "    lis = sorted(dic.items(),key = lambda x:x[1])\n",
    "    for k in range(len(lis)):\n",
    "        kk = len(lis)-k-1\n",
    "        if lis[kk][0] not in out_data:\n",
    "            out_data.append(lis[kk][0])\n",
    "            break\n",
    "    a = out_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1785, 1591, 337, 972, 236, 64, 1444]\n"
     ]
    }
   ],
   "source": [
    "#print the serial numbers of streamlines that should be retained after compression when we need 8 streamlines after compression\n",
    "print(out_data[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1785, 1591, 337, 972, 236, 64, 1444, 1524, 1575, 1443, 1772, 806, 778, 983, 571]\n"
     ]
    }
   ],
   "source": [
    "print(out_data[0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1785, 1591, 337, 972, 236, 64, 1444, 1524, 1575, 1443, 1772, 806, 778, 983, 571, 817, 673, 639, 917, 650, 698, 1793, 567, 1538, 402, 1970, 1775, 1990, 1878, 1988, 1517]\n"
     ]
    }
   ],
   "source": [
    "print(out_data[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1785, 1591, 337, 972, 236, 64, 1444, 1524, 1575, 1443, 1772, 806, 778, 983, 571, 817, 673, 639, 917, 650, 698, 1793, 567, 1538, 402, 1970, 1775, 1990, 1878, 1988, 1517, 1983, 1547, 1979, 1879, 1961, 1676, 1910, 1658, 1551, 391, 1523, 721, 741, 542, 1975, 1642, 2001, 1540, 1996, 1387, 1995, 945, 1994, 1633, 1968, 1646, 1966, 1660, 1993, 985, 1989, 1830]\n"
     ]
    }
   ],
   "source": [
    "print(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the npy array-out_data according to the number of streamlines after compression firstly\n",
    "#stored the serial numbers\n",
    "out_list = np.zeros(2087)# the same length as the experimental data\n",
    "for i in range(len(out_list)):\n",
    "    if i in out_data:\n",
    "        out_list[i] = 1\n",
    "np.save('kitchen_compression_64.npy',out_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
